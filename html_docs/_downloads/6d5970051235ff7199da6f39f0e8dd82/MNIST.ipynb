{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# MNIST Examples\n\nWe illustrate some basic considerations while manipulating the class :class:`codpy.kernel.Kernel` classes , applying it to the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) problem.\nIt illustrates the following interpolation / extrapolation method\n\n    $$f_{k,\\theta}(\\cdot) = K(\\cdot, Y) \\theta, \\quad \\theta = K(X, Y)^{-1} f(X),$$\nwhere\n    - $K(X, Y)$ is the Gram matrix, see :func:`codpy.kernel.Kernel.Knm`\n    - $K(X, Y)^{-1} = (K(Y, X)K(X, Y))^{-1}K(Y,X)$ is computed as a least-square method without regularization terms, see :func:`codpy.kernel.Kernel.get_knm_inv`.\n\nThis notebook illustrates various choices+ for the set $Y$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport random\n\nimport numpy as np\nimport pandas as pd\n\n# A multi scale kernel method.\nfrom sklearn.metrics import confusion_matrix\n\nimport codpy.core as core\nfrom codpy.clustering import MiniBatchkmeans\n\n# We use a custom hot encoder for performances reasons.\nfrom codpy.data_processing import hot_encoder\n\n# Standard codpy kernel class.\nfrom codpy.kernel import KernelClassifier\n\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"32\"\nos.environ[\"OMP_NUM_THREADS\"] = \"32\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We pick-up MNIST data using tensorflow (tf). pip install tf on your installation prior running this notebook !\n\nNote :\n\n           - The MNIST corresponds to features $X\\in \\mathbb{R}^{60000,784}$. Each image, represented as $28\\times 28$ black and white pixel is a feature described as a vector in dimension $D=784$.\n\n           - We hot encode the MNIST classes : $f(X) \\in \\mathbb{R}^{60000,10}$ is defined as\n                       $$f(x) = (\\delta_i(c(x)), \\quad i=1,\\ldots,10,$$\n              where $c(x)$ is the indice of the label of the class, and $\\delta_i(j) = \\{i==j\\}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_MNIST_data(N=-1):\n    import tensorflow as tf\n\n    (x, fx), (z, fz) = tf.keras.datasets.mnist.load_data()\n    x, z = x / 255.0, z / 255.0\n    x, z, fx, fz = (\n        x.reshape(len(x), -1),\n        z.reshape(len(z), -1),\n        fx.reshape(len(fx), -1),\n        fz.reshape(len(fz), -1),\n    )\n    fx, fz = (\n        hot_encoder(pd.DataFrame(data=fx), cat_cols_include=[0], sort_columns=True),\n        hot_encoder(pd.DataFrame(data=fz), cat_cols_include=[0], sort_columns=True),\n    )\n    x, fx, z, fz = (x, fx.values, z, fz.values)\n    if N != -1:\n        indices = random.sample(range(x.shape[0]), N)\n        x, fx = x[indices], fx[indices]\n\n    return x, fx, z, fz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We perform basic tests on MNIST results : confusion matrix and scores.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def show_confusion_matrix(z, fz, predictor=None, cm=True):\n    f_z = predictor(z)\n    fz, f_z = fz.argmax(axis=-1), f_z.argmax(axis=-1)\n    out = confusion_matrix(fz, f_z)\n    if cm:\n        print(\"confusion matrix:\")\n        print(out)\n    print(\"score MNIST:\", np.trace(out) / np.sum(out))\n    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run codpy silently on/off.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "core.kernel_interface.set_verbose(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set variables and pick MNIST data for the test.\nN_MNIST_pics is used to pick a smaller set than the original one.\nThe training set is `x,fx`, the test set is `z,fz`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N_clusters = 100\nN_MNIST_pics = 5000\nx, fx, z, fz = get_MNIST_data(N_MNIST_pics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First pick $Y$ at random. Output confusion matrix for two sets : the training set $X$ and the test set $Z$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "indices = np.random.choice(range(x.shape[0]), size=N_clusters)\ny, fy = x[indices], fx[indices]\npredictor = KernelClassifier(x=x, y=y, fx=fx)\nprint(\"Output with the training set - reproductibility test:\")\nshow_confusion_matrix(x, fx, predictor, cm=False)\nprint(\"Output with the test set :\")\nshow_confusion_matrix(z, fz, predictor)\nprint(\"Discrepancy(x,y):\", predictor.discrepancy(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select $Y$ having a lowest discrepancy with a greedy algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictor = KernelClassifier(x=x, fx=fx).greedy_select(\n    N=N_clusters, all=True, start_indices={indices[0]}\n)\nprint(\"Reproductibility test:\")\nshow_confusion_matrix(x, fx, predictor, cm=False)\nprint(\"Performance test:\")\nshow_confusion_matrix(z, fz, predictor, cm=False)\nprint(\"Discrepancy(x,y):\", predictor.discrepancy(predictor.get_y()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select $Y$ adapted to $f(x)$ using a greedy algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictor = KernelClassifier(x=x, fx=fx).greedy_select(N=N_clusters, fx=fx, all=True)\nprint(\"Reproductibility test:\")\nshow_confusion_matrix(x, fx, predictor, cm=False)\nprint(\"Performance test:\")\nshow_confusion_matrix(z, fz, predictor, cm=False)\nprint(\"Discrepancy(x,y):\", predictor.discrepancy(predictor.get_y()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select $Y$ using a k-means algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = MiniBatchkmeans(x, N=N_clusters).cluster_centers_\npredictor = KernelClassifier(x=x, y=y, fx=fx)\nprint(\"Reproductibility test:\")\nshow_confusion_matrix(x, fx, predictor, cm=False)\nprint(\"Performance test:\")\nshow_confusion_matrix(z, fz, predictor, cm=False)\nprint(\"Discrepancy(x,y):\", predictor.discrepancy(predictor.get_y()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}