
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gallery_examples\MNIST.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_gallery_examples_MNIST.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_examples_MNIST.py:


MNIST Examples
==========================

We illustrate some basic considerations while manipulating the class :class:`codpy.kernel.Kernel` classes , applying it to the `MNIST <https://en.wikipedia.org/wiki/MNIST_database>`_ problem.
It illustrates the following interpolation / extrapolation method

    $$f_{k,\theta}(\cdot) = K(\cdot, Y) \theta, \quad \theta = K(X, Y)^{-1} f(X),$$
where
    - $K(X, Y)$ is the Gram matrix, see :func:`codpy.kernel.Kernel.Knm`
    - $K(X, Y)^{-1} = (K(Y, X)K(X, Y))^{-1}K(Y,X)$ is computed as a least-square method without regularization terms, see :func:`codpy.kernel.Kernel.get_knm_inv`.

This notebook illustrates various choices+ for the set $Y$

.. GENERATED FROM PYTHON SOURCE LINES 15-33

.. code-block:: Python



    import os
    import pandas as pd
    import numpy as np
    import random
    # We use a custom hot encoder for performances reasons.
    from codpy.data_processing import hot_encoder
    # Standard codpy kernel class.
    from codpy.kernel import Kernel,KernelClassifier
    import codpy.core as core
    # A multi scale kernel method.
    from sklearn.metrics import confusion_matrix
    from codpy.clustering import *

    os.environ["OPENBLAS_NUM_THREADS"] = "32"
    os.environ["OMP_NUM_THREADS"] = "32"








.. GENERATED FROM PYTHON SOURCE LINES 34-43

We pick-up MNIST data using tensorflow (tf). pip install tf on your installation prior running this notebook !

Note : 

           - The MNIST corresponds to features $X\in \mathbb{R}^{60000,784}$. Each image, represented as $28\times 28$ black and white pixel is a feature described as a vector in dimension $D=784$.

           - We hot encode the MNIST classes : $f(X) \in \mathbb{R}^{60000,10}$ is defined as 
                       $$f(x) = (\delta_i(c(x)), \quad i=1,\ldots,10,$$
              where $c(x)$ is the indice of the label of the class, and $\delta_i(j) = \{i==j\}$.

.. GENERATED FROM PYTHON SOURCE LINES 43-66

.. code-block:: Python

    def get_MNIST_data(N=-1):
        import tensorflow as tf

        (x, fx), (z, fz) = tf.keras.datasets.mnist.load_data()
        x, z = x / 255.0, z / 255.0
        x, z, fx, fz = (
            x.reshape(len(x), -1),
            z.reshape(len(z), -1),
            fx.reshape(len(fx), -1),
            fz.reshape(len(fz), -1),
        )
        fx, fz = (
            hot_encoder(pd.DataFrame(data=fx), cat_cols_include=[0], sort_columns=True),
            hot_encoder(pd.DataFrame(data=fz), cat_cols_include=[0], sort_columns=True),
        )
        x, fx, z, fz = (x, fx.values, z, fz.values)
        if N != -1:
            indices = random.sample(range(x.shape[0]), N)
            x, fx = x[indices], fx[indices]

        return x, fx, z, fz









.. GENERATED FROM PYTHON SOURCE LINES 67-68

We perform basic tests on MNIST results : confusion matrix and scores.

.. GENERATED FROM PYTHON SOURCE LINES 68-80

.. code-block:: Python


    def show_confusion_matrix(z, fz, predictor=None, cm=True):
        f_z = predictor(z)
        fz, f_z = fz.argmax(axis=-1), f_z.argmax(axis=-1)
        out = confusion_matrix(fz, f_z)
        if cm:
            print("confusion matrix:")
            print(out)
        print("score MNIST:", np.trace(out) / np.sum(out))
        pass









.. GENERATED FROM PYTHON SOURCE LINES 81-82

Run codpy silently on/off.

.. GENERATED FROM PYTHON SOURCE LINES 82-84

.. code-block:: Python

    core.kernel_interface.set_verbose(False)








.. GENERATED FROM PYTHON SOURCE LINES 85-88

Set variables and pick MNIST data for the test.
N_MNIST_pics is used to pick a smaller set than the original one.
The training set is `x,fx`, the test set is `z,fz`.

.. GENERATED FROM PYTHON SOURCE LINES 88-92

.. code-block:: Python

    N_clusters=100
    N_MNIST_pics=5000
    x, fx, z, fz = get_MNIST_data(N_MNIST_pics)








.. GENERATED FROM PYTHON SOURCE LINES 93-94

First pick $Y$ at random. Output confusion matrix for two sets : the training set $X$ and the test set $Z$ 

.. GENERATED FROM PYTHON SOURCE LINES 94-103

.. code-block:: Python

    indices = np.random.choice(range(x.shape[0]),size=N_clusters)
    y,fy = x[indices],fx[indices]
    predictor = KernelClassifier(x=x, y=y,fx=fx)
    print("Output with the training set - reproductibility test:")
    show_confusion_matrix(x, fx, predictor,cm=False)
    print("Output with the test set :")
    show_confusion_matrix(z, fz, predictor)
    print("Discrepancy(x,y):", predictor.discrepancy(y))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Output with the training set - reproductibility test:
    score MNIST: 0.8892
    Output with the test set :
    confusion matrix:
    [[ 952    0    1    0    0    7   11    1    8    0]
     [   0 1113    1    3    1    1    5    0   11    0]
     [  15   14  864   26   25    0   25   28   32    3]
     [   4    2   21  905    2   14    9   20   23   10]
     [   1    9    2    0  837    1   27    3    7   95]
     [  17    5    6   68   14  706   30   17   18   11]
     [  15    6    2    0    8   17  908    1    1    0]
     [   4   29   20    3   23    1    2  907   10   29]
     [  13    7   11   37   12   20   18   13  831   12]
     [  16   12   12   15   44    7   11   24    9  859]]
    score MNIST: 0.8882
    Discrepancy(x,y): 0.006256564711011714




.. GENERATED FROM PYTHON SOURCE LINES 104-105

Select $Y$ having a lowest discrepancy with a greedy algorithm.

.. GENERATED FROM PYTHON SOURCE LINES 105-112

.. code-block:: Python

    predictor = KernelClassifier(x=x,fx=fx).greedy_select(N=N_clusters,all=True,start_indices={indices[0]})
    print("Reproductibility test:")
    show_confusion_matrix(x, fx, predictor,cm=False)
    print("Performance test:")
    show_confusion_matrix(z, fz, predictor,cm=False)
    print("Discrepancy(x,y):", predictor.discrepancy(predictor.get_y()))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Reproductibility test:
    score MNIST: 0.87
    Performance test:
    score MNIST: 0.8653
    Discrepancy(x,y): 0.005726346772445601




.. GENERATED FROM PYTHON SOURCE LINES 113-114

Select $Y$ adapted to $f(x)$ using a greedy algorithm.

.. GENERATED FROM PYTHON SOURCE LINES 114-122

.. code-block:: Python

    predictor = KernelClassifier(x=x,fx=fx).greedy_select(N=N_clusters,fx=fx,all=True)
    print("Reproductibility test:")
    show_confusion_matrix(x, fx, predictor,cm=False)
    print("Performance test:")
    show_confusion_matrix(z, fz, predictor,cm=False)
    print("Discrepancy(x,y):", predictor.discrepancy(predictor.get_y()))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Reproductibility test:
    score MNIST: 0.8958
    Performance test:
    score MNIST: 0.8836
    Discrepancy(x,y): 0.008965316825990999




.. GENERATED FROM PYTHON SOURCE LINES 123-124

Select $Y$ using a k-means algorithm.

.. GENERATED FROM PYTHON SOURCE LINES 124-133

.. code-block:: Python

    y = MiniBatchkmeans(x,N=N_clusters).cluster_centers_
    predictor = KernelClassifier(x=x,y=y,fx=fx)
    print("Reproductibility test:")
    show_confusion_matrix(x, fx, predictor,cm=False)
    print("Performance test:")
    show_confusion_matrix(z, fz, predictor,cm=False)
    print("Discrepancy(x,y):", predictor.discrepancy(predictor.get_y()))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    C:\Informatique\python\lib\site-packages\sklearn\cluster\_kmeans.py:1848: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 8192 or by setting the environment variable OMP_NUM_THREADS=20
      warnings.warn(
    Reproductibility test:
    score MNIST: 0.9234
    Performance test:
    score MNIST: 0.9133
    Discrepancy(x,y): 0.05923800086968101





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 8.987 seconds)


.. _sphx_glr_download_gallery_examples_MNIST.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: MNIST.ipynb <MNIST.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: MNIST.py <MNIST.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: MNIST.zip <MNIST.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
