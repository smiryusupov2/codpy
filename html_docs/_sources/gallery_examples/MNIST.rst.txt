
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gallery_examples\MNIST.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_gallery_examples_MNIST.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_examples_MNIST.py:


MNIST Examples
==========================

We illustrate some basic considerations while manipulating the class :class:`codpy.kernel.Kernel` classes , applying it to the `MNIST <https://en.wikipedia.org/wiki/MNIST_database>`_ problem.
It illustrates the following interpolation / extrapolation method

    $$f_{k,\theta}(\cdot) = K(\cdot, Y) \theta, \quad \theta = K(X, Y)^{-1} f(X),$$
where
    - $K(X, Y)$ is the Gram matrix, see :func:`codpy.kernel.Kernel.Knm`
    - $K(X, Y)^{-1} = (K(Y, X)K(X, Y))^{-1}K(Y,X)$ is computed as a least-square method without regularization terms, see :func:`codpy.kernel.Kernel.get_knm_inv`.

This notebook illustrates various choices+ for the set $Y$

.. GENERATED FROM PYTHON SOURCE LINES 15-32

.. code-block:: Python



    import os
    import pandas as pd
    import numpy as np
    import random
    # We use a custom hot encoder for performances reasons.
    from codpy.data_processing import hot_encoder
    # Standard codpy kernel class.
    from codpy.kernel import Kernel
    # A multi scale kernel method.
    from codpy.multiscale_kernel import *
    from sklearn.metrics import confusion_matrix

    os.environ["OPENBLAS_NUM_THREADS"] = "32"
    os.environ["OMP_NUM_THREADS"] = "32"








.. GENERATED FROM PYTHON SOURCE LINES 33-42

We pick-up MNIST data using tensorflow (tf). pip install tf on your installation prior running this notebook !

Note : 

           - The MNIST corresponds to features $X\in \mathbb{R}^{60000,784}$. Each image, represented as $28\times 28$ black and white pixel is a feature described as a vector in dimension $D=784$.

           - We hot encode the MNIST classes : $f(X) \in \mathbb{R}^{60000,10}$ is defined as 
                       $$f(x) = (\delta_i(c(x)), \quad i=1,\ldots,10,$$
              where $c(x)$ is the indice of the label of the class, and $\delta_i(j) = \{i==j\}$.

.. GENERATED FROM PYTHON SOURCE LINES 42-65

.. code-block:: Python

    def get_MNIST_data(N=-1):
        import tensorflow as tf

        (x, fx), (z, fz) = tf.keras.datasets.mnist.load_data()
        x, z = x / 255.0, z / 255.0
        x, z, fx, fz = (
            x.reshape(len(x), -1),
            z.reshape(len(z), -1),
            fx.reshape(len(fx), -1),
            fz.reshape(len(fz), -1),
        )
        fx, fz = (
            hot_encoder(pd.DataFrame(data=fx), cat_cols_include=[0], sort_columns=True),
            hot_encoder(pd.DataFrame(data=fz), cat_cols_include=[0], sort_columns=True),
        )
        x, fx, z, fz = (x, fx.values, z, fz.values)
        if N != -1:
            indices = random.sample(range(x.shape[0]), N)
            x, fx = x[indices], fx[indices]

        return x, fx, z, fz









.. GENERATED FROM PYTHON SOURCE LINES 66-67

We perform basic tests on MNIST results : confusion matrix and scores.

.. GENERATED FROM PYTHON SOURCE LINES 67-79

.. code-block:: Python


    def show_confusion_matrix(z, fz, predictor=None, cm=True):
        f_z = predictor(z)
        fz, f_z = fz.argmax(axis=-1), f_z.argmax(axis=-1)
        out = confusion_matrix(fz, f_z)
        if cm:
            print("confusion matrix:")
            print(out)
        print("score MNIST:", np.trace(out) / np.sum(out))
        pass









.. GENERATED FROM PYTHON SOURCE LINES 80-81

Run codpy silently on/off.

.. GENERATED FROM PYTHON SOURCE LINES 81-83

.. code-block:: Python

    core.kernel_interface.set_verbose(False)








.. GENERATED FROM PYTHON SOURCE LINES 84-87

Set variables and pick MNIST data for the test.
N_MNIST_pics is used to pick a smaller set than the original one.
The training set is `x,fx`, the test set is `z,fz`.

.. GENERATED FROM PYTHON SOURCE LINES 87-91

.. code-block:: Python

    N_clusters=100
    N_MNIST_pics=5000
    x, fx, z, fz = get_MNIST_data(N_MNIST_pics)








.. GENERATED FROM PYTHON SOURCE LINES 92-93

First pick $Y$ at random. Output confusion matrix for two sets : the training set $X$ and the test set $Z$ 

.. GENERATED FROM PYTHON SOURCE LINES 93-102

.. code-block:: Python

    indices = np.random.choice(range(x.shape[0]),size=N_clusters)
    y,fy = x[indices],fx[indices]
    predictor = KernelClassifier(x=x, y=y,fx=fx)
    print("Output with the training set - reproductibility test:")
    show_confusion_matrix(x, fx, predictor,cm=False)
    print("Output with the test set :")
    show_confusion_matrix(z, fz, predictor)
    print("Discrepancy(x,y):", predictor.discrepancy(y))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Output with the training set - reproductibility test:
    score MNIST: 0.8886
    Output with the test set :
    confusion matrix:
    [[ 912    0    2    3    1   25   30    1    6    0]
     [   0 1110    3    3    1    0    6    0   12    0]
     [   9   14  894   15   14    4   18   28   33    3]
     [   5    6   30  888    1   24    9   16   20   11]
     [   1    6    6    0  848    3   26    2    8   82]
     [  13    3    5   62   14  715   27   14   26   13]
     [  11    4    5    1   13   19  905    0    0    0]
     [   3   33   37    0   11    2    2  894    8   38]
     [  14   12   14   36   16   19   20   10  809   24]
     [  12   10    2   14   59    8    4   29   16  855]]
    score MNIST: 0.883
    Discrepancy(x,y): 0.00698489536680813




.. GENERATED FROM PYTHON SOURCE LINES 103-104

Select $Y$ having a lowest discrepancy with a greedy algorithm.

.. GENERATED FROM PYTHON SOURCE LINES 104-111

.. code-block:: Python

    predictor = KernelClassifier(x=x,fx=fx).greedy_select(N=N_clusters,all=True,start_indices={indices[0]})
    print("Reproductibility test:")
    show_confusion_matrix(x, fx, predictor,cm=False)
    print("Performance test:")
    show_confusion_matrix(z, fz, predictor,cm=False)
    print("Discrepancy(x,y):", predictor.discrepancy(predictor.get_y()))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Reproductibility test:
    score MNIST: 0.8852
    Performance test:
    score MNIST: 0.8814
    Discrepancy(x,y): 0.005822551390662956




.. GENERATED FROM PYTHON SOURCE LINES 112-113

Select $Y$ adapted to $f(x)$ using a greedy algorithm.

.. GENERATED FROM PYTHON SOURCE LINES 113-121

.. code-block:: Python

    predictor = KernelClassifier(x=x,fx=fx).greedy_select(N=N_clusters,fx=fx,all=True)
    print("Reproductibility test:")
    show_confusion_matrix(x, fx, predictor,cm=False)
    print("Performance test:")
    show_confusion_matrix(z, fz, predictor,cm=False)
    print("Discrepancy(x,y):", predictor.discrepancy(predictor.get_y()))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Reproductibility test:
    score MNIST: 0.9012
    Performance test:
    score MNIST: 0.8887
    Discrepancy(x,y): 0.011791424288440489




.. GENERATED FROM PYTHON SOURCE LINES 122-123

Select $Y$ using a k-means algorithm.

.. GENERATED FROM PYTHON SOURCE LINES 123-132

.. code-block:: Python

    y = MiniBatchkmeans(x,N=N_clusters).cluster_centers_
    predictor = KernelClassifier(x=x,y=y,fx=fx)
    print("Reproductibility test:")
    show_confusion_matrix(x, fx, predictor,cm=False)
    print("Performance test:")
    show_confusion_matrix(z, fz, predictor,cm=False)
    print("Discrepancy(x,y):", predictor.discrepancy(predictor.get_y()))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    C:\Informatique\python\lib\site-packages\sklearn\cluster\_kmeans.py:1848: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 8192 or by setting the environment variable OMP_NUM_THREADS=20
      warnings.warn(
    Reproductibility test:
    score MNIST: 0.9226
    Performance test:
    score MNIST: 0.9158
    Discrepancy(x,y): 0.05901122908524592




.. GENERATED FROM PYTHON SOURCE LINES 133-134

Select a multi scale kernel method where the centers are given by a k-mean algorithm.

.. GENERATED FROM PYTHON SOURCE LINES 134-142

.. code-block:: Python

    N_partition=5
    predictor = MultiScaleKernelClassifier(x=x,fx=fx,N=N_partition)
    print("Reproductibility test:")
    show_confusion_matrix(x, fx, predictor,cm=False)
    print("Performance test:")
    show_confusion_matrix(z, fz, predictor,cm=False)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    C:\Informatique\python\lib\site-packages\sklearn\cluster\_kmeans.py:1848: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 8192 or by setting the environment variable OMP_NUM_THREADS=20
      warnings.warn(
    Reproductibility test:
    score MNIST: 1.0
    Performance test:
    score MNIST: 0.9624




.. GENERATED FROM PYTHON SOURCE LINES 143-144

Select a multi scale kernel where the centers are given by a greedy search algorithm.

.. GENERATED FROM PYTHON SOURCE LINES 144-149

.. code-block:: Python

    predictor = MultiScaleKernelClassifier(x=x,fx=fx,N=N_partition,method=GreedySearch)
    print("Reproductibility test:")
    show_confusion_matrix(x, fx, predictor,cm=False)
    print("Performance test:")
    show_confusion_matrix(z, fz, predictor,cm=False)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Reproductibility test:
    score MNIST: 1.0
    Performance test:
    score MNIST: 0.9624





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 37.563 seconds)


.. _sphx_glr_download_gallery_examples_MNIST.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: MNIST.ipynb <MNIST.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: MNIST.py <MNIST.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: MNIST.zip <MNIST.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
